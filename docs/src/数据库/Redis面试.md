[TOC]

#### 1、Redis的应用场景

1）热点数据的访问

2）限时业务的运用
redis中可以使用expire命令设置一个键的生存时间，到时间后redis会删除它。利用这一特性可以运用在限时的优惠活动信息、手机验证码等业务场景。 

3）计数器相关问题
redis由于incrby命令可以实现原子性的递增，所以可以运用于高并发的秒杀活动、分布式序列号的生成、具体业务还体现在比如限制一个手机号发多少条短信、一个接口一分钟限制多少请求、一个接口一天限制调用多少次等等。

 4）排行榜相关问题
关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助redis的SortedSet进行热点数据的排序。 

 5）分布式锁
这个主要利用redis的setnx命令进行，setnx："set if not exists"就是如果不存在则成功设置缓存同时返回1，否则返回0 ，这个特性在俞你奔远方的后台中有所运用，因为我们服务器是集群的，定时任务可能在两台机器上都会运行，所以在定时任务中首先 通过setnx设置一个lock，如果成功设置则执行，如果没有成功设置，则表明该定时任务已执行。 当然结合具体业务，我们可以给这个lock加一个过期时间，比如说30分钟执行一次的定时任务，那么这个过期时间设置为小于30分钟的一个时间 就可以，这个与定时任务的周期以及定时任务执行消耗时间相关。

当然我们可以将这个特性运用于其他需要分布式锁的场景中，结合过期时间主要是防止死锁的出现。

 6）延时操作
下面我举个该特性的应用场景。 比如在订单生产后我们占用了库存，10分钟后去检验用户是够真正购买，如果没有购买将该单据设置无效，同时还原库存。 

于redis自2.8.0之后版本提供Keyspace Notifications功能，允许客户订阅Pub/Sub频道，以便以某种方式接收影响Redis数据集的事件。 所以我们对于上面的需求就可以用以下解决方案，我们在订单生产时，设置一个key，同时设置10分钟后过期， 我们在后台实现一个监听器，监听key的实效，监听到key失效时将后续逻辑加上。 当然我们也可以利用rabbitmq、activemq等消息中间件的延迟队列服务实现该需求。

 7）分页、模糊搜索

 redis的set集合中提供了一个zrangebylex方法，语法如下：
ZRANGEBYLEX key min max [LIMIT offset count]
通过ZRANGEBYLEX zset - + LIMIT 0 10 可以进行分页数据查询，其中- +表示获取全部数据
zrangebylex key min max 这个就可以返回字典区间的数据，利用这个特性可以进行模糊查询功能，这个也是目前我在redis中发现的唯一一个支持对存储内容进行模糊查询的特性。
前几天我通过这个特性，对学校数据进行了模拟测试，学校数据60万左右，响应时间在700ms左右，比mysql的like查询稍微快一点，但是由于它可以避免大量的数据库io操作，所以总体还是比直接mysql查询更利于系统的性能保障。

 8）点赞、好友等相互关系的存储

 Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 又或者在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。

这个在奶茶活动中有运用，就是利用set存储用户之间的点赞关联的，另外在点赞前判断是否点赞过就利用了sismember方法，当时这个接口的响应时间控制在10毫秒内，十分高效。

 9）队列
由于redis有list push和list pop这样的命令，所以能够很方便的执行队列操作。 

 #### 2、Redis支持的数据类型(必考)

List(列表) 

Set(无序集合) 

OrderSet(有序集合)  又称zset

String(字符串) 

hashs(哈希) 

| 类型                 | 简介                                                   | 特性                                                         | 场景                                                         |
| -------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String(字符串)       | 二进制安全                                             | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M | ---                                                          |
| Hash(字典)           | 键值对集合,即编程语言中的Map类型                       | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性                                     |
| List(列表)           | 链表(双向链表)                                         | 增删快,提供了操作某一段元素的API                             | 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列          |
| Set(集合)            | 哈希表实现,元素不重复                                  | 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 | 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 |
| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score,元素按score有序排列 | 数据插入集合时,已经进行天然排序                              | 1、排行榜 2、带权重的消息队列                                |

 #### 3、zset跳表的数据结构（必考）

二分搜索是数组搜索的策略 那么二分搜索的策略能否用到链表上？

跳表是从链表发展而来？有用到二分的思想

对于单链表来说，我们查找某个数据，只能从头到尾遍历链表，此时时间复杂度是 ○(n)。 

![1599118272836](C:\Users\lenovo\AppData\Local\Temp\1599118272836.png)

单链表 

那么怎么提高单链表的查找效率呢？看下图，对链表建立一级 `索引`，每两个节点提取一个结点到上一级，被抽出来的这级叫做 `索引` 或 `索引层`。 

 ![1599118293376](C:\Users\lenovo\AppData\Local\Temp\1599118293376.png)

 第一级索引 

开发中经常会用到一种处理方式，hashmap 中存储的值类型是一个 list，这里就可以把索引当做 hashmap 中的键，将每 2 个结点看成每个键对应的值 list。 

所以要找到13，就不需要将16前的结点全遍历一遍，只需要遍历索引，找到13，然后发现下一个结点是17，那么16一定是在 [13,17] 之间的，此时在13位置下降到原始链表层，找到16，加上一层索引后，查找一个结点需要遍历的结点个数减少了，也就是说查找效率提高了 

那么我们再加一级索引呢？
跟前面建立一级索引的方式相似，我们在第一级索引的基础上，每两个结点就抽出一个结点到第二级索引。此时再查找16，只需要遍历 6 个结点了，需要遍历的结点数量又减少了。 

![1599118430833](C:\Users\lenovo\AppData\Local\Temp\1599118430833.png)

 第二级索引 

当结点数量多的时候，这种添加索引的方式，会使查询效率提高的非常明显、

![1599118491562](C:\Users\lenovo\AppData\Local\Temp\1599118491562.png)

这种链表加多级索引的结构，就是跳表。 

跳表参考链接:<https://blog.csdn.net/qq_38545713/article/details/105439688> 

#### 4、Redis的数据过期策略（必考）

**3种过期策略 **

**1、定时删除 **

含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除 

优点：保证内存被尽快释放 

缺点 :

> 若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key 
>
> 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重 
>
> 没人用 

**2、惰性删除 **

含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。 

优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了） 

缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存） 

**3、定期删除 **

含义：每隔一段时间执行一次删除(在redis.conf配置文件设置hz，1s刷新的频率)过期key操作 

优点： 

- 通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点
- 定期删除过期key--处理"惰性删除"的缺点

缺点 

- 在内存友好方面，不如"定时删除"
- 在CPU时间友好方面，不如"惰性删除"

难点

- 合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了

定期删除可以通过：

- 第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，值越大说明刷新频率越快，最Redis性能损耗也越大） 
- 第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略



**注意：**

- 上边所说的数据库指的是内存数据库，默认情况下每一台redis服务器有16个数据库（关于数据库的设置，看下边代码），默认使用0号数据库，所有的操作都是对0号数据库的操作，关于redis数据库的存储结构，查看 第八章 Redis数据库结构与读写原理

~~~
# 设置数据库数量。默认为16个库，默认使用DB 0，可以使用"select 1"来选择一号数据库
# 注意：由于默认使用0号数据库，那么我们所做的所有的缓存操作都存在0号数据库上，
# 当你在1号数据库上去查找的时候，就查不到之前set过得缓存
# 若想将0号数据库上的缓存移动到1号数据库，可以使用"move key 1"
~~~

- memcached只是用了惰性删除，而Redis同时使用了惰性删除与定期删除，这也是二者的一个不同点（可以看做是redis优于memcached的一点）
- 对于惰性删除而言，并不是只有获取key的时候才会检查key是否过期，在某些设置key的方法上也会检查（eg.setnx key2 value2：该方法类似于memcached的add方法，如果设置的key2已经存在，那么该方法返回false，什么都不做；如果设置的key2不存在，那么该方法设置缓存key2-value2。假设调用此方法的时候，发现redis中已经存在了key2，但是该key2已经过期了，如果此时不执行删除操作的话，setnx方法将会直接返回false，也就是说此时并没有重新设置key2-value2成功，所以对于一定要在setnx执行之前，对key2进行过期检查）

定时删除和定期删除为主动删除：Redis会定期主动淘汰一批已过去的key

惰性删除为被动删除：用到的时候才会去检验key是不是已过期，过期就删除

**惰性删除为redis服务器内置策略 ** 

**redis采用的过期策略 **

定期删除 + 惰性删除、

惰性删除流程 

> 在进行get或setnx等操作时，先检查key是否过期，
>
> 若过期，删除key，然后执行相应操作；
>
> 若没过期，直接执行相应操作

 定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key） 

> 遍历每个数据库（就是redis.conf中配置的"database"数量，默认为16） 
>
> 检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体时下边的描述）
>
> - 如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历
> - 随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key
> - 判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。

 

**内存淘汰机制 **

1. noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
2. allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
3. allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
4. volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。
5. volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。
6. volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。

参考资料：<https://www.cnblogs.com/xuliangxing/p/7151812.html> 

#### 5、Redis为什么是单线程的

redis 核心就是 如果我的数据全都在内存里，我单线程的去操作 就是效率最高的，为什么呢，因为多线程的本质就是 CPU 模拟出来多个线程的情况，这种模拟出来的情况就有一个代价，就是上下文的切换，对于一个内存的系统来说，它没有上下文的切换就是效率最高的。redis 用 单个CPU 绑定一块内存的数据，然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它是单线程处理这个事。在内存的情况下，这个方案就是最佳方案 —— 阿里 沈询 

因为一次CPU上下文的切换大概在 1500ns 左右。

从内存中读取 1MB 的连续数据，耗时大约为 250us，假设1MB的数据由多个线程读取了1000次，那么就有1000次时间上下文的切换，

那么就有1500ns * 1000 = 1500us ，我单线程的读完1MB数据才250us ,你光时间上下文的切换就用了1500us了，我还不算你每次读一点数据 的时间，

**那什么时候用多线程的方案呢？ **

下层的存储等慢速的情况。比如磁盘   IOPS是每秒的读写速度

内存是一个 IOPS 非常高的系统，因为我想申请一块内存就申请一块内存，销毁一块内存我就销毁一块内存，内存的申请和销毁是很容易的。而且内存是可以动态的申请大小的。

磁盘的特性是：IOPS很低很低，但吞吐量很高。这就意味着，**大量的读写操作都必须攒到一起，再提交到磁盘的时候，性能最高。**

为什么呢？

如果我有一个事务组的操作（就是几个已经分开了的事务请求，比如写读写读写，这么五个操作在一起），在内存中，因为IOPS非常高，我可以一个一个的完成，但是如果在磁盘中也有这种请求方式的话，

我第一个写操作是这样完成的：我先在硬盘中寻址，大概花费10ms，然后我读一个数据可能花费1ms然后我再运算（忽略不计），再写回硬盘又是10ms ，总共21ms

第二个操作去读花了10ms, 第三个又是写花费了21ms ,然后我再读10ms, 写21ms ，五个请求总共花费83ms，这还是最理想的情况下，这如果在内存中，大概1ms不到。

**所以对于磁盘来说，它吞吐量这么大，那最好的方案肯定是我将N个请求一起放在一个buff里，然后一起去提交。**

**方法就是用异步：将请求和处理的线程不绑定，请求的线程将请求放在一个buff里，然后等buff快满了，处理的线程再去处理这个buff。然后由这个buff 统一的去写入磁盘，或者读磁盘，这样效率就是最高。**

java里的 IO不就是这么干的么~

对于慢速设备，这种处理方式就是最佳的，慢速设备有磁盘，网络 ，SSD 等等，

多线程 ，异步的方式处理这些问题非常常见，大名鼎鼎的netty 就是这么干的。

#### 6、Redis的LRU过期策略的具体实现 

~~~
public class LRUCache<K,V> extends LinkedHashMap<K,V> {
    private int cacheSize;
    public LRUCache(int cacheSize){
        super(10,0.75f,true);
        //设置hashmap大小，true是让linkedhashmap按照访问顺序排序
        this.cacheSize = cacheSize;
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        //当map中数量大于指定缓存个数的时候，自动删除最老的数据
        return size()>cacheSize;
    }
}
~~~

#### 7、如何解决Redis缓存雪崩、缓存穿透问题 缓存与数据库双写一致

**7.1 我们为什么要去缓存 **

![redis缓存](https://gitee.com/WyEdward/images/raw/master/img/redis缓存.png)



现在有个问题 如果我们的缓存挂掉了，这意味着我们的全部请求都跑去数据库了。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190112194701574.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDMzNzE2,size_16,color_FFFFFF,t_70)

在前面学习我们都知道Redis不可能把所有的数据都缓存起来(内存昂贵且有限)，**所以Redis需要对数据设置过期时间**，并采用的是**惰性删除+定期删除**两种策略对过期键删除。Redis对过期键的策略+持久化

**7.2 如果**缓存数据设置的过期时间是相同的**，并且Redis恰好将这部分数据全部删光了。这就会导致在这段时间内，这些缓存**同时失效**，全部请求到数据库中。**

**这就是缓存雪崩： **

 Redis挂掉了，请求全部走数据库。 对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。 缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！ 

**如何解决缓存雪崩 ？**

对于“对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。”这种情况，非常好解决：

**解决方法**：

1、在缓存的时候给**过期时间加上一个随机值**，这样就会大幅度的减少缓存在同一时间过期。

2、对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路：
事发前：实现Redis的高可用(**主从架构+Sentinel（哨兵） 或者Redis Cluster（集群）)，尽量避免Redis挂掉这种情况发生**。
事发中：万一Redis真的挂了，我们可以设置**本地缓存**(ehcache)+**限流**(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的)
事发后：**redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据**。

**7.3 什么是缓存穿透？**

比如，我们有一张数据库表，ID都是从1开始的(正数)：

但是可能有黑**客想把我的数据库搞垮**，每次请求的ID都是**负数**。这会导致我的缓存就没用了，请求全部都找数据库去了，但数据库也没有这个值啊，所以每次都返回空出去。

> 缓存穿透是指查询一个一定不存在的数据。由于缓存不命中，并且出于容错考虑，如果从数据库查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，失去了缓存的意义。 

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190112195442942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDMzNzE2,size_16,color_FFFFFF,t_70)

这就是缓存穿透： **请求的数据在缓存大量不命中，导致请求走数据库。缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！** 

如何解决缓存穿透？

解决缓存穿透也有两种方案：

1、由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用**布隆过滤器(BloomFilter)或者压缩filter提前拦截**，不合法就**不让这个请求到数据库层**！
2、当我们从数据库找不到的时候，我们也将这个**空对象设置到缓存**里边去。下次再请求的时候，就可以从缓存里边获取了。
**这种情况我们一般会将空对象设置一个较短的过期时间**。

**7.4 缓存与数据库双写一致 **

对于读操作

> 上面讲缓存穿透的时候也提到了：如果从数据库查不到数据则不写入缓存。
> 一般我们对**读操作**的时候有这么一个固定的套路：
>
> 如果我们的数据在缓存里边有，那么就直接取缓存的。
> 如果缓存里没有我们想要的数据，我们会先去查询数据库，然后将**数据库查出来的数据写到缓存中**。
> 最后将数据返回给请求

什么是缓存与数据库双写一致？

如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要**更新时候**呢？**各种情况很可能就造成数据库和缓存的数据不一致了**。

**这里不一致指的是：数据库的数据跟缓存的数据不一致**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190112200231115.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDMzNzE2,size_16,color_FFFFFF,t_70)

从理论上说，只要我们设置了**键的过期时间**，我们就能保证缓存和数据库的数据最终是一致的。因为只要缓存数据过期了，就会被删除。随后读的时候，因为缓存里没有，就可以查数据库的数据，然后将数据库查出来的数据写入到缓存中。

除了设置过期时间，我们还需要做更多的措施来**尽量避免**数据库与缓存处于不一致的情况发生。

**对于更新操作 **

一般来说，执行更新操作时，我们会有两种选择：
先操作数据库，再操作缓存
先操作缓存，再操作数据库
首先，要明确的是，无论我们选择哪个，我们都希望这**两个操作要么同时成功，要么同时失败**。所以，这会演变成一个**分布式事务**的问题。

所以，如**果原子性被破坏**了，可能会有以下的情况：

**操作数据库成功了，操作缓存失败了。操作缓存成功了，操作数据库失败了。**

如果第一步已经失败了，我们直接返回Exception出去就好了，第二步根本不会执行。

**操作缓存 **

操作缓存也有两种方案：

**更新缓存**

**删除缓存**

一般我们都是采取删除缓存缓存策略的，原因如下：

> 1、 高并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就更加容易导致数据库与缓存数据不一致问题。(**删除缓存直接和简单很多)** 2、如果每次更新了数据库，都要更新缓存【这里指的是频繁更新的场景，**这会耗费一定的性能**】，倒不如**直接删除掉**。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(体现懒加载) 

基于这两点，对于缓存在更新时而言，都是建议执行**删除**操作！

正常的情况是这样的：

先操作数据库，成功；
再删除缓存，也成功；

如果原子性被破坏了：

> 第一步成功(操作数据库)，第二步失败(删除缓存)，会导致数据库里是新数据，而缓存里是旧数据。
> 如果第一步(操作数据库)就失败了，我们可以直接返回错误(Exception)，不会出现数据不一致。

如果在高并发的场景下，出现数据库与缓存数据不一致的**概率特别低**，也不是没有：

> 1、 缓存刚好失效
> 2、线程A查询数据库，得一个旧值
> 3、线程B将新值写入数据库
> 4、线程B删除缓存
> 5、线程A将查到的旧值写入缓存
> 要达成上述情况，还是说一句概率特别低：

因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

**删除缓存失败的解决思路：**

> 将需要删除的key发送到消息队列中
> 自己消费消息，获得需要删除的key
> 不断重试删除操作，直到成功

**先删除缓存，再更新数据库 **

> 正常情况是这样的：
> 先删除缓存，成功；
> 再更新数据库，也成功；

如果原子性被破坏了：

> 第一步成功(删除缓存)，第二步失败(更新数据库)，数据库和缓存的数据还是一致的。
> 如果第一步(删除缓存)就失败了，我们可以直接返回错误(Exception)，数据库和缓存的数据还是一致的。

 看起来是很美好，但是我们在并发场景下分析一下，就知道还是有问题的了：

> 线程A删除了缓存
> 线程B查询，发现缓存已不存在
> 线程B去数据库查询得到旧值
> 线程B将旧值写入缓存
> 线程A将新值写入数据库

所以也会导致数据库和缓存不一致的问题。

**并发下解决数据库与缓存不一致的思路：**

将删除缓存、修改数据库、读取缓存等的操作积压到队列里边，实现串行化。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190112204026380.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NDMzNzE2,size_16,color_FFFFFF,t_70)

对比两种策略

先删除缓存，再更新数据库 在高并发下表现不如意，在原子性被破坏时表现优异 先更新数据库，再删除缓存(Cache Aside Pattern设计模式) 在高并发下表现优异，在原子性被破坏时表现不如意 

参考资料 <https://blog.csdn.net/qq_35433716/article/details/86375506> 

#### 8、Redis的持久化机制

Redis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。 

**1、快照(RDB) **

快照是一次全量备份， 快照是内存数据的二进制序列化形式，在存储上非常紧凑 

我们知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。

在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API。

这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这尼玛要怎么搞？

那该怎么办呢？

Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化，这个机制很有意思，也很少人知道。多进程 COW 也是鉴定程序员知识广度的一个重要指标。

**fork（多进程）**

Redis 在持久化时会调用 glibc 的函数`fork`产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。这时你可以将父子进程想像成一个连体婴儿，共享身体。这是 Linux 操作系统的机制，为了节约内存资源，所以尽可能让它们共享起来。在进程分离的一瞬间，内存的增长几乎没有明显变化。

 用 Python 语言描述进程分离的逻辑如下。`fork`函数会在父子进程同时返回，在父进程里返回子进程的 pid，在子进程里返回零。如果操作系统内存资源不足，pid 就会是负数，表示`fork`失败。 

子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。

这个时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。

随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。

子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。

**2、AOF **

AOF 日志是连续的增量备份 AOF 日志记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。 

**原理 **

AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。

假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内存数据结构的状态。

Redis 会在收到客户端修改指令后，进行参数校验进行逻辑处理后，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先执行指令才将日志存盘。这点不同于leveldb、hbase等存储引擎，它们都是先存储日志再做逻辑处理。

Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。

 **AOF重写 **

Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。  

**BGREWRITEAOF命令，这个命令会通过移除AOF文件中的冗余命令来重写（rewrite）AOF文件，使AOF文件的体积变得尽可能地小。**

**AOF重写：(1) 随着AOF文件越来越大，里面会有大部分是重复命令或者可以合并的命令（100次incr = set key 100）(2) 重写的好处：减少AOF日志尺寸，减少内存占用，加快数据库恢复时间。**

fsync

AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了内核为文件描述符分配的一个内存缓存中，然后内核会异步将脏数据刷回到磁盘的。

这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个时候就会出现日志丢失。那该怎么办？

Linux 的`glibc`提供了`fsync(int fd)`函数可以将指定文件的内容强制从内核缓存刷到磁盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘 IO 操作，它很慢！如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。

所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。

Redis 同样也提供了另外两种策略，一个是永不 fsync——让操作系统来决定何时同步磁盘，很不安全，另一个是来一个指令就 fsync 一次——非常慢。但是在生产环境基本不会使用，了解一下即可。

**Redis 4.0 混合持久化 **

重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。

Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。 

混合持久化的时候，aof 文件开头是 rdb 的格式, 先加载 rdb 内容再加载剩余的 aof。 打开AOF文件之后，首先读取5个字符，如果是"REDIS"，那么就说明这是一个混合持久化的AOF文件。正确的RDB格式一定是以"REDIS"开头，而纯AOF格式则一定以"*"开头的。

“REDIS”开头，就会进入rdbLoadRio函数就以约定好的协议解析加载rdb数据，直至遇到RDB_OPCODE_EOF结束标记，返回loadAppendOnlyFile函数继续以AOF格式解析文件，直到结束整个加载过程完成。

 

![img](https://user-gold-cdn.xitu.io/2018/7/10/164821272ae19ebb?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

 

于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

参考资料：<https://www.cnblogs.com/xxj-bigshow/p/10314414.html> 

#### 9、Redis为什么那么快？（必考）

完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗 

#### 10、Redis怎么实现分布式锁？

分布式锁需要解决的问题

- 互斥性：任意时刻只能有一个客户端拥有锁，不能同时多个客户端获取
- 安全性：锁只能被持有该锁的用户删除，而不能被其他用户删除
- 死锁：获取锁的客户端因为某些原因而宕机，而未能释放锁，其他客户端无法获取此锁，需要有机制来避免该类问题的发生
- 容错：当部分节点宕机，客户端仍能获取锁或者释放锁

**1、如何实现分布式锁 **

a. `SETNX key value` :如果key不存在,则创建并赋值 (不正确的方法 不能保证原子性)

- 时间复杂度: 0(1)
- 返回值:设置成功,返回1;设置失败,返回0。

> 但是此时我们获取的key是长期有效的，所以我们应该如何解决长期有效的问题呢？

如何解决SETNX长期有效的问题

`EXPIRE key seconds`

- 设置key的生存时间,当key过期时(生存时间为0) ,会被自动删除
- 缺点：原子性得不到满足



b.`SET key value [EX seconds] [PX milliseconds] [NX|XX]` (正确的方法)

- EX second :设置键的过期时间为second秒
- PX millisecond :设置键的过期时间为millisecond毫秒
- NX :只在键不存在时,才对键进行设置操作
- XX:只在键已经存在时,才对键进行设置操作
- SET操作成功完成时,返回OK ,否则返回nil

可以直接通过 `set key value px milliseconds nx` 命令实现加锁， 通过Lua脚本实现解锁。 

~~~
//获取锁（unique_value可以是UUID等）
SET resource_name unique_value NX PX  30000

//释放锁（lua脚本中，一定要比较value，防止误解锁）
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
~~~

代码解释

- set 命令要用 `set key value px milliseconds nx`，替代 `setnx + expire` 需要分两次执行命令的方式，保证了原子性，
- value 要具有唯一性，可以使用`UUID.randomUUID().toString()`方法生成，用来标识这把锁是属于哪个请求加的，在解锁的时候就可以有依据；
- 释放锁时要验证 value 值，防止误解锁；
- 通过 Lua 脚本来避免 Check And Set 模型的并发问题，因为在释放锁的时候因为涉及到多个Redis操作 （利用了eval命令执行Lua脚本的原子性）；

**加锁代码分析 **

首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，用来标识这把锁是属于哪个请求加的，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。 

**解锁代码分析** 

将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。在执行的时候，首先会获取锁对应的value值，检查是否与requestId相等，如果相等则解锁（删除key）。 

存在的风险

如果存储锁对应key的那个节点挂了的话，就可能存在丢失锁的风险，导致出现多个客户端持有锁的情况，这样就不能实现资源的独享了。

1. 客户端A从master获取到锁
2. 在master将锁同步到slave之前，master宕掉了（Redis的主从同步通常是异步的）。
   主从切换，slave节点被晋级为master节点
3. 客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。导致存在同一时刻存不止一个线程获取到锁的情况。

**多节点redis实现的分布式锁算法(RedLock):有效防止单点故障** 

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

 

![[07期]Redis中是如何实现分布式锁的？](https://www.javazhiyin.com/wp-content/uploads/2019/10/java7-1571978049.png)

**Redisson实现 **

Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。

Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。

**Redisson 分布式重入锁用法**

Redisson 支持单点模式、主从模式、哨兵模式、集群模式，这里以单点模式为例：

~~~
// 1.构造redisson实现分布式锁必要的Config
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:5379").setPassword("123456").setDatabase(0);
// 2.构造RedissonClient
RedissonClient redissonClient = Redisson.create(config);
// 3.获取锁对象实例（无法保证是按线程的顺序获取到）
RLock rLock = redissonClient.getLock(lockKey);
try {
    /**
     * 4.尝试获取锁
     * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败
     * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完）
     */
    boolean res = rLock.tryLock((long)waitTimeout, (long)leaseTime, TimeUnit.SECONDS);
    if (res) {
        //成功获得锁，在这里处理业务
    }
} catch (Exception e) {
    throw new RuntimeException("aquire lock fail");
}finally{
    //无论如何, 最后都要解锁
    rLock.unlock();
}
~~~

分布式重入锁的流程图        其他分布式锁都是不可重入的 否则会造成死锁

加锁流程图 

![[07期]Redis中是如何实现分布式锁的？](https://www.javazhiyin.com/wp-content/uploads/2019/10/java4-1571978050.png)

解锁流程图 

![[07期]Redis中是如何实现分布式锁的？](https://www.javazhiyin.com/wp-content/uploads/2019/10/java6-1571978050.png)

参考 <https://www.cnblogs.com/javazhiyin/p/11737403.html> 

#### 11、redis如何做内存优化

1、缩减键值对象 

缩减键（key）和值（value）的长度，

- key长度：如在设计键时，在完整描述业务情况下，键值越短越好。
- value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。以JAVA为例，内置的序列化方式无论从速度还是压缩比都不尽如人意，这时可以选择更高效的序列化工具，如: protostuff，kryo等，下图是JAVA常见序列化工具空间压缩对比。

2、共享对象池 

对象共享池指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。 除了整数值对象，其他类型如list,hash,set,zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。 

3、字符串优化

4、编码优化

5、控制key的数量



#### 12、Redis主从模式和哨兵模式和集群模式

主从模式

主节点用于服务，从节点用于数据备份（不能跳过主节点直接给从节点写入），在主节点关机后，从节点可变为主节点替代已关闭的主节点提供服务。

为了保持主从节点数据一致性，在每次给主节点写入数据后，都会给从节点做一次数据更新。

\###不足1：从节点变为主节点需要人工手动修改redis.properties配置，有点不方便

\###不足2：主从模式写入能力有限（因为在单机模式下，且每次给主节点写入数据，都要给从节点更新），当从节点变多时，每个从节点都要更新，会花费更多的时间，效率会变慢。

​       这时可采用树形结构，主节点只需更新一层从节点，后面的从节点由从节点负责更新，提高更新效率。

哨兵模式

哨兵模式改善了主从模式的第一个不足。

结构：相对主从模式在结构上在客户端和节点中多了哨兵

原理：在多个哨兵运行的时候会一直ping所有节点，当master主节点挂了后，哨兵会检测出客户端到这几个从节点最快的节点，自动修改配置文件，把这个从节点切换成主节点，无需人工干预。

注意点：哨兵必须为奇数个，如3个哨兵（选举问题、投票问题）

**一、Redis的主从复制 **

通过执行slaveof命令或设置slaveof选项，让一个服务器去复制另一个服务器的数据。被复制的服务器称为：Master主服务；对主服务器进行复制的服务器称为：Slave从服务器。主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。

主从复制问题：当master down，需要手动将一台slave使用slaveof no one提升为master要实现自动，就需要redis哨兵。

实现原理步骤：

1. 从服务器向主服务器发送SYNC命令
2. 主服务器收到SYNC命令后，执行BGSAVE命令，在后台生成RDB文件，使用缓冲区记录从现在开始执行的所有的写命令。
3. 当主服务器的BGSAVE命令执行完毕后，主服务器后将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。
4. 主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。

![img](https://www.pianshen.com/images/640/212f45b98632c3277f091d767b6545e8.png)redis主从复制

**二、Redis的哨兵（Sentinel）**

为了解决Redis的主从复制的不支持高可用性能，Redis实现了Sentinel哨兵机制解决方案。由一个或多个Sentinel去监听任意多个主服务以及主服务器下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线的主服务器属下的某个从服务器升级为新的主服务器，然后由新的主服务器代替已经下线的从服务器，并且Sentinel可以互相监视。

![img](https://www.pianshen.com/images/50/6c069155c4a2171ef1ca96303abe209a.png)

​									监视状态下的主从模式

![img](https://www.pianshen.com/images/840/4c565e32e6846fc78b9ddcec0445a048.png)

​											主服务器下线

当有多个Sentinel，在进行监视和转移主从服务器时，Sentinel之间会自己首先进行选举，选出Sentinel的leader来进行执行任务。 

**三、Redis集群 **

集群是Redis提供的分布式数据库方案，集群通过分片来进行数据共享，并提供复制和故障转移功能。一个Redis集群通常由多个节点组成；最初，每个节点都是独立的，需要将独立的节点连接起来才能形成可工作的集群。

Redis 集群是一个可以在多个 Redis 节点之间进行数据共享的设施（installation）。 

Cluster Nodes命令和Cluster Meet命令，添加和连接节点形成集群。

![img](https://www.pianshen.com/images/691/fd16cb941b503ffc458c53324d75899b.png)节点握手连接成集群

 

Redis中的集群分为主节点和从节点。其中主节点用于处理槽；而从节点用于复制某个主节点，并在被复制的主节点下线时，代替下线的主节点继续处理命令请求。

![img](https://www.pianshen.com/images/911/a498328d3f9cb774cc3975576b4063e7.png)

 

参考：<https://www.pianshen.com/article/1023276171/> 

#### 13、Redis常见的性能问题

1.master写内存快照，seve命令调度rdbsave函数，会阻塞主线程的工程，当快照比较大的时候对性能的影响是非常大的，会间断性暂停服务 。所以master最好不要写内存快照。

2.master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响master重启时的恢复速度。master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化，如果数据比较关键，某个slave开启AOF备份数据，策略每秒为同步一次。

3.master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂的服务暂停现象。

4.redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，slave和master最好在同一个局域网内。

#### 14、 热点key重建问题

这个问题是指，某个key高并发读，如果刚好碰上到期更新，会导致多个线程重建key，导致db负载过大，应用雪崩。要解决这个隐患，可以给重建key设置互斥锁，确保同一时间只有一个线程重建缓存。另外，还有一个办法就是，不设置过期时间，然后在逻辑上去控制，即逻辑上记录一个过期时间，如果到了这个过期时间，缓存还能用，只是要通知缓存重建线程去重建。

#### 15、Redis和memcached的区别

1. 存储方式上：memcache会把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。redis有部分数据存在硬盘上，这样能保证数据的持久性。
2. 数据支持类型上：memcache对数据类型的支持简单，只支持简单的key-value，，而redis支持五种数据类型。
3. 用底层模型不同：它们之间底层实现方式以及与客户端之间通信的应用协议不一样。redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。
4. value的大小：redis可以达到1GB，而memcache只有1MB。